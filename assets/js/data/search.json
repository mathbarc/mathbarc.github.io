[ { "title": "Capturing data from Kinect v2 using OpenCV", "url": "/posts/kinectv2-opencv-openni2/", "categories": "3D Reconstruction, LiDAR", "tags": "kinect, opencv, pcl, openni, 3d", "date": "2022-08-15 10:00:00 -0300", "snippet": "What is Kinect?Kinect is a movement sensor developed for use on Xbox 360 and Xbox One by Prime Sense in a collaboration with Microsoft. The device contains microphones, RGB cameras, infrared emissors and a monocromátic CMOS sensor for sampling infrared. By calibrating the infrared emissor and CMOS sensor it is possible to obtain depth maps and reconstruct the scene.The device was created as a natural interface for users to interact with video games without the need for physical controllers. It is capable to detect pose of up to 4 people simultaneously.In this article are the steps necessary to access Kinect data using OpenCV on Linux.Materials Kinect v2 Kinect v2 Adapter PC with linuxDependenciesDuring the wrinting of this article, two operational systems were used: Ubuntu 20.04 and Ubuntu 22.04 and because of that it will be shown the APT commands used to install pre-compiled libraries. For users of other OS it will be show compilation steps for the dependencies.OpenNIOpenNI (Open Natural Interaction) is an Open Source project that aims to improve standardization of natural user interfaces. It provides an API that encapsulates hardware details and facilitates integration with applications.This library was mainly maintained by PrimeSense, but its original repository was discontinued when the company was bought by Apple in 2013. Since then old partners and employees from PrimeSense made a fork from OpenNI 2 which is currently maintained by StructureIO. Repo: https://github.com/structureio/OpenNI2 APT Commmand: apt install libopenni2-dev openni2-utilsOpenCVOpenCV (Open Computer Vision) is an Open Source library that reunites computer vision algorithms on different areas: image processing, 3D reconstruction, optimization, clustering, tracking, descriptors, matching, object recognition and deep learning. It has support for multiple programming languages like: C++, python, java e MATLAB. Repo: https://github.com/opencv/opencv APT Commmand: apt install libopencv-devThe following steps are necessary to compile a version of OpenCV with support to OpenNI2:git clone https://github.com/opencv/opencv.gitgit clone https://github.com/opencv/opencv_contrib.gitcd opencv_contribgit checkout 4.6.0cd ../opencvgit checkout 4.6.0mkdir buildcd buildcmake -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTING=OFF -DBUILD_PERF_TESTS=OFF -DOPENCV_ENABLE_NONFREE=OFF -DOPENCV_EXTRA_MODULES=../opencv_contrib/modules -DWITH_OPENNI2=ON ..make -j 4sudo make installPCLPCL (Point Clout Library) is a C++ library specialized in processing point clouds. It provides implementations of filters, key point selection, surface reconstruction, sensor communication and visualization. Repositório: https://github.com/PointCloudLibrary/pcl Comando APT: apt install libpcl-devMaking it workThe libraries in the last session allow high level programming that provides functions to recover and reconstruct 3D data. However, to make them work we firstly need to compile a driver that manages communication between OS and Kinect. To do so it is possible to utilize the project libfreenect, an open source Kinect driver developed mostly for linux but capable of being compiled on windows.As the main focus of this article is to utilize the Kinect version 2, on this session the steps necessary to compile and configure the LibFreenect2 are shown.Compiling libfreenect2git clone https://github.com/OpenKinect/libfreenect2.gitcd libfreenect2git checkout v0.2.1mkdir buildcd buildcmake -DBUILD_OPENNI2_DRIVER=ON -DCMAKE_BUILD_TYPE=Release ..make -j 4sudo make installsudo make install-openni2Allow access to deviceAfter compilation and installation of the project, it is necessary to grant users access to Kinect device, otherwise root permission will be needed to capture data from the sensor. It can be done by executing the following commands:cd libfreenect2sudo cp ./platform/linux/udev/90-kinect2.rules /etc/udev/rules.d/It is necessary to disconnect the Kinect sensor from the USB port and reconnect again for changes to take place.Testing with NiViewer2After following the steps above the command NiViewer2 can be used to check if the environment is correct configurated:sudo apt install openni2-utils # caso não tenha sido instalado aindaNiViewer2The execution of the above command is expected to look like the following image:[Info] [Freenect2Impl] enumerating devices...[Info] [Freenect2Impl] 10 usb devices connected[Info] [Freenect2Impl] found valid Kinect v2 @2:2 with serial 067886733447[Info] [Freenect2Impl] found 1 devices[Info] [Freenect2DeviceImpl] opening...[Info] [Freenect2DeviceImpl] transfer pool sizes rgb: 20*16384 ir: 60*8*33792[Info] [Freenect2DeviceImpl] opened[Info] [Freenect2DeviceImpl] starting...[Info] [Freenect2DeviceImpl] submitting rgb transfers...[Info] [Freenect2DeviceImpl] submitting depth transfers...[Info] [Freenect2DeviceImpl] started[Info] [DepthPacketStreamParser] 32 packets were lost[Info] [DepthPacketStreamParser] 13 packets were lost[Info] [TurboJpegRgbPacketProcessor] avg. time: 9.53263ms -&gt; ~104.903HzProgram SampleIf the environment is correct configured, on this section is provided a sample code using OpenCV to capture data from sensor and PCL to visualize the point cloud. After compiling and executing the program it is expected a view like the video of the last session.Source Codefind_package(OpenCV 4 COMPONENTS core highgui videoio imgcodecs)if(${OpenCV_FOUND})else() find_package(OpenCV 2 COMPONENTS core highgui REQUIRED)endif()find_package(PCL COMPONENTS visualization REQUIRED)set(OPENNI_CAPTURE_INCLUDE_DIRS \t${OpenCV_INCLUDE_DIRS} ${PCL_INCLUDE_DIRS})file(GLOB OPENNI_CAPTURE_SOURCES main.cpp)include_directories(${OPENNI_CAPTURE_INCLUDE_DIRS})add_executable(openni-capture ${OPENNI_CAPTURE_SOURCES})target_link_libraries(openni-capture ${OpenCV_LIBS} ${PCL_LIBRARIES})#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;iostream&gt;#include &lt;pcl/visualization/cloud_viewer.h&gt;#include &lt;fstream&gt;cv::VideoCapture cap(1, cv::CAP_OPENNI2); // Configures cv::VideoCapture to open device 1 using OpenNI2void getPointCloud(pcl::visualization::PCLVisualizer&amp; viewer){ viewer.removeAllPointClouds(); // Cleans previous point cloud on view cv::Mat pointCloudFrame, frame; cap.grab(); // Grabs a sensor reading cap.retrieve(pointCloudFrame, cv::CAP_OPENNI_POINT_CLOUD_MAP); // Recovers point cloud on matrix format from sensor data cap.retrieve(frame, cv::CAP_OPENNI_BGR_IMAGE); // Obtains color information aligned with point cloud pcl::visualization::CloudViewer::ColorCloud* cloud = new pcl::visualization::CloudViewer::ColorCloud(); for(int i = 0; i&lt;pointCloudFrame.rows; i++) // For each point on the matrix { for(int j = 0; j&lt;pointCloudFrame.cols; j++) // For each point on the matrix { cv::Vec3b color = frame.at&lt;cv::Vec3b&gt;(i,j); // Gets point color pcl::PointXYZRGB point(color[2], color[1], color[0]); // Creates a PCL point containing color cv::Vec3f coords = pointCloudFrame.at&lt;cv::Vec3f&gt;(i,j); // Gets X,Y,Z position of point point.x = coords[0]; // Sets coodinate on point point.y = coords[1]; // Sets coodinate on point point.z = coords[2]; // Sets coodinate on point cloud-&gt;push_back(point); // Adds point on point cloud } } viewer.addPointCloud(pcl::visualization::CloudViewer::ColorCloud::ConstPtr(cloud)); // Sends a point cloud to be rendered on screen}int main(int argc, char** argv){ if(!cap.isOpened()) return -1; cap.set(cv::CAP_OPENNI_DEPTH_GENERATOR_REGISTRATION, 1); // Configures OpenNI to generate point clouds with color information pcl::visualization::CloudViewer viewer(\"point cloud\"); // Initializes a Point Cloud Viewer interface viewer.runOnVisualizationThread(getPointCloud); // Defines callback function to render scene while(!viewer.wasStopped()); // Waits for window closure cap.release(); // Closes communication with device return 0;}Result In case of any doubts or ideas send me a email, Matheus Barcelos de Oliveira Computer Engineer " }, { "title": "Using ESP32 for Speech Recognition", "url": "/posts/using-esp32-for-speech-recognition/", "categories": "Embedded Systems, IoT", "tags": "speech recognition, esp, messaging, iot", "date": "2020-06-29 10:00:00 -0300", "snippet": "This article will present steps to utilize ESP32 in cotrolling a lamp using voice commands.Supplies A ESP32 device: Mercado Livre, Amazon; A Relay with 5v trigger: Mercado Livre, Amazon; A computer to host the MQTT broker and capture audio from a microfone.Sending Messages with MQTTTo create a messaging system that connect the PC and ESP32 device it is going to be used the MQTT (Message Queuing Telemetry Transport) Protocol.The MQTT is a lightweight protocol that aims to solve telemetry problems for small sensors and mobile devices through a TCP/IP network. This protocol implements the Publisher-Subscriber model, in which elements send information to a topic (Publisher) and elements consult new information on a topic (Subscriber). There is also a middleman responsible to host and manage data queues, called Broker on this protocol.So the first step is to install the Mosquitto MQTT broker on a machine: Debian/Ubuntu: sudo apt install mosquitto Windows: https://mosquitto.org/download/A Simple Speech Recognition for Voice CommandsWith the MQTT broker installed it is possible to create a python script that will capture audio from a microphone, check the voice commands that were said and publish the desired state of the lamp to the controller that will be shown on the next section.The script will need the following dependencies:pip install SpeechRecognition paho-mqttWith the dependencies installed we are able to run the following script:import speech_recognition as sr # import the libraryimport paho.mqtt.client as mqttprint(sr.Microphone.list_microphone_names()) client = mqtt.Client(client_id = 'speech', protocol = mqtt.MQTTv31) # starts mqtt clientclient.connect(\"BROKER_IP\", 1883) # connects to brokerr = sr.Recognizer() # initialize recognizerwith sr.Microphone() as source: # mention source it will be either Microphone or audio files. print(\"Say the voice command: \") while True: r.adjust_for_ambient_noise(source) audio = r.listen(source, phrase_time_limit=5) # listen to the source try: text = r.recognize_google(audio, language=\"en-US\") # use recognizer to convert our audio into text part. print(\"{}\".format(text)) if text == \"turn on the lamp\": client.publish(\"lamp0/state\",\"1\",qos=0) elif text == \"turn off the lamp\": client.publish(\"lamp0/state\",\"0\",qos=0) except: print(\"Sorry could not recognize your words, please repeat\") # In case of voice not recognized clearlyMaking ESP32 Receive Voice CommandsConfiguring the IDEThe fist thing to do here is to configure the ArduinoIDE to work with ESP32.Although this device is not a Arduino device, there are some compatibility packages that allows programming using this IDE. To gain access to these packages it is necessary to include the following lines in the field present on Files &gt; Preferences &gt; Additional URLs, as the following image:https://arduino.esp8266.com/stable/package_esp8266com_index.json,https://dl.espressif.com/dl/package_esp32_index.json After adding the Urls above, it is possible to install the ESP32 module by accessing Tools &gt; Boards &gt; Board Manager. After clicking on Board Manager a window will open and we can write ESP32 on the filter as following:After installing the module we have to select ESP32 as the target board for the IDE, we can do so by accessing the following path Tools &gt; Boards &gt; ESP32 Arduino &gt; ESP32 Dev Module.With the board configured, it is still necessary to install the MQTT package for ESP32 devices. To do so we can access Tools &gt; Manage Libraries and then search for ESPMQTT as follows:Embedded CodeAfter finishing the IDE setup above we can go to the code that will control a Relay from MQTT messages. On the code bellow there are three itens that need to be replaced: WIFI_SSID: It should be the name of you wifi network WIFI_PASSWORD: It should be your wifi password BROKER_IP: It should be the IP of the pc with mosquitto installed./* SimpleMQTTClient.c The purpose of this exemple is to illustrate a simple handling of MQTT and Wifi connection. Once it connects successfully to a Wifi network and a MQTT broker, it subscribe to a topic and send a message to it. It will also send a message delayed 5 seconds later.*/#include \"EspMQTTClient.h\"EspMQTTClient client( \"WIFI_SSID\", \"WIFI_PASSWORD\", \"BROKER_IP\", // MQTT Broker server ip \"\", // Can be omitted if not needed \"\", // Can be omitted if not needed \"esp32\", // Client name that uniquely identify your device 1883 // The MQTT port, default to 1883. this line can be omitted);int outputPin = 15; // GPIO Pin for relay controlvoid setup(){ Serial.begin(9600); // Optionnal functionnalities of EspMQTTClient : client.enableDebuggingMessages(); // Enable debugging messages sent to serial output client.enableHTTPWebUpdater(); // Enable the web updater. User and password default to values of MQTTUsername and MQTTPassword. These can be overrited with enableHTTPWebUpdater(\"user\", \"password\"). client.enableLastWillMessage(\"TestClient/lastwill\", \"I am going offline\"); // You can activate the retain flag by setting the third parameter to true pinMode(outputPin, OUTPUT); digitalWrite(outputPin, HIGH);}void subscriptionCallBack(const String &amp; payload) { digitalWrite(outputPin, (payload == \"0\")?(HIGH):(LOW)); Serial.print(\"outputPin: \"); Serial.println(payload);}// This function is called once everything is connected (Wifi and MQTT)void onConnectionEstablished(){ // Subscribe to \"lamp0/state\" and display received message to Serial client.subscribe(\"lamp0/state\", subscriptionCallBack);}void loop(){ client.loop();}ResultAfter compiling the code on the ESP32 board, we can run the python code provided on this post to begin controlling devices with voice command. In case of any doubts or ideas send me a email, Matheus Barcelos de Oliveira Computer Engineer " } ]
